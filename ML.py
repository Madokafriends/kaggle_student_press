import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from torch.utils.data import TensorDataset, DataLoader
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch_directml

class MLP(nn.Module):
    def __init__(self, in_dim, num_classes):
        super().__init__()
        self.net = nn.Sequential(
            nn.BatchNorm1d(in_dim),              # input BN

            nn.Linear(in_dim, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),

            nn.Linear(128, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),

            nn.Linear(128, num_classes)          # logits
        )

    def forward(self, x):
        return self.net(x)

class BLS(nn.Module):
    def __init__(self, in_dim, num_classes, feature_nodes=20, enhancement_nodes=40):
        super().__init__()
        # ç‰¹å¾èŠ‚ç‚¹
        self.feature_layer = nn.Sequential(
            nn.Linear(in_dim, feature_nodes),
            nn.Tanh()
        )
        
        # å¢å¼ºèŠ‚ç‚¹
        self.enhancement_layer = nn.Sequential(
            nn.Linear(feature_nodes, enhancement_nodes),
            nn.ReLU()
        )
        
        # è¾“å‡ºå±‚
        self.output_layer = nn.Linear(feature_nodes + enhancement_nodes, num_classes)
        
    def forward(self, x):
        features = self.feature_layer(x)
        enhancements = self.enhancement_layer(features)
        
        # è¿æ¥ç‰¹å¾å’Œå¢å¼ºèŠ‚ç‚¹
        combined = torch.cat((features, enhancements), dim=1)
        return self.output_layer(combined)

class AttentionMLP(nn.Module):
    def __init__(self, in_dim, num_classes):
        super().__init__()
        self.embedding = nn.Sequential(
            nn.Linear(in_dim, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Dropout(0.3)
        )
        
        self.attention = nn.MultiheadAttention(
            embed_dim=128, 
            num_heads=4, 
            dropout=0.2,
            batch_first=True
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Dropout(0.3),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x):
        # æ·»åŠ è™šæ‹Ÿåºåˆ—ç»´åº¦ (batch_size, seq_len=1, features)
        x = x.unsqueeze(1)  
        
        # ç‰¹å¾åµŒå…¥
        embedded = self.embedding(x)
        
        # è‡ªæ³¨æ„åŠ›
        attn_output, _ = self.attention(embedded, embedded, embedded)
        attn_output = attn_output.squeeze(1)  # ç§»é™¤åºåˆ—ç»´åº¦
        
        return self.classifier(attn_output)
    
class EarlyStopping:
    def __init__(self, patience=10, min_delta=1e-3, save_path="best.pt"):
        self.patience = patience
        self.min_delta = min_delta
        self.wait = 0
        self.best = np.inf
        self.best_path = save_path
        self.stopped = False

    def step(self, val_loss, model):
        improved = (self.best - val_loss) > self.min_delta
        if improved:
            self.best = val_loss
            self.wait = 0
            torch.save(model.state_dict(), self.best_path)  # checkpoint
        else:
            self.wait += 1
            if self.wait >= self.patience:
                self.stopped = True
        return improved

# è®­ç»ƒå‡½æ•° (åŒ…å«Early Stoppingå’Œå­¦ä¹ ç‡è°ƒåº¦)
def train_model(model, train_loader, valid_loader, criterion, optimizer, 
               scheduler, early_stopping, epochs=200, verbose=1):
    """
    è®­ç»ƒæ¨¡å‹å¹¶è¿”å›å†å²è®°å½•
    :param model: è¦è®­ç»ƒçš„æ¨¡å‹
    :param train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
    :param valid_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
    :param criterion: æŸå¤±å‡½æ•°
    :param optimizer: ä¼˜åŒ–å™¨
    :param scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
    :param early_stopping: æ—©åœå›è°ƒ
    :param epochs: æœ€å¤§è®­ç»ƒè½®æ•°
    :param verbose: æ—¥å¿—è¯¦ç»†ç¨‹åº¦ (0: æ— , 1: æ¯epoch, 2: æ¯batch)
    :return: åŒ…å«è®­ç»ƒå†å²çš„å­—å…¸
    """
    history = {
        'epoch': [],
        'lr': [],
        'train_loss': [], 'val_loss': [],
        'train_acc': [], 'val_acc': []
    }
    
    print(f"å¼€å§‹è®­ç»ƒï¼Œä½¿ç”¨è®¾å¤‡: {device}")
    print(f"æ¨¡å‹ç»“æ„:\n{model}")
    print(f"è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)} | éªŒè¯æ ·æœ¬: {len(valid_loader.dataset)}")
    
    for epoch in range(epochs):
        # ===== è®­ç»ƒé˜¶æ®µ =====
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, labels) in enumerate(train_loader):
            inputs, labels = inputs.to(device), labels.to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # è®¡ç®—æŒ‡æ ‡
            running_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
            
            # è¯¦ç»†æ—¥å¿—
            if verbose > 1 and (batch_idx % 50 == 0 or batch_idx == len(train_loader)-1):
                batch_acc = 100. * correct / total
                print(f'Epoch {epoch+1}/{epochs} | Batch {batch_idx+1}/{len(train_loader)} | '
                      f'Loss: {loss.item():.4f} | Acc: {batch_acc:.2f}%')
        
        # è®¡ç®—epochè®­ç»ƒæŒ‡æ ‡
        train_loss = running_loss / total
        train_acc = 100. * correct / total
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        
        # ===== éªŒè¯é˜¶æ®µ =====
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for inputs, labels in valid_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item() * inputs.size(0)
                _, predicted = outputs.max(1)
                val_correct += predicted.eq(labels).sum().item()
                val_total += labels.size(0)
        
        val_loss = val_loss / val_total
        val_acc = 100. * val_correct / val_total
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step(val_loss)
        current_lr = optimizer.param_groups[0]['lr']
        history['lr'].append(current_lr)
        history['epoch'].append(epoch+1)
        
        # æ‰“å°epochæ‘˜è¦
        if verbose > 0:
            print(f'\nEpoch {epoch+1}/{epochs} | '
                  f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '
                  f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | '
                  f'LR: {current_lr:.6f}')
        
        # Early Stoppingæ£€æŸ¥
        improved = early_stopping.step(val_loss, model)
        if improved:
            print(f'ğŸŒŸ Validation loss improved to {val_loss:.4f}, saving model...')
        
        # æ£€æŸ¥æ˜¯å¦æ—©åœ
        if early_stopping.stopped:
            print(f'\nğŸš¨ Early stopping triggered at epoch {epoch+1}')
            print(f'Best validation loss: {early_stopping.best:.4f}')
            break
    
    # è®­ç»ƒç»“æŸæ€»ç»“
    print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {early_stopping.best:.4f}")
    if early_stopping.stopped:
        print(f"åœ¨ {len(history['epoch'])} ä¸ªepochåæ—©åœ")
    else:
        print(f"å®Œæˆæ‰€æœ‰ {epochs} ä¸ªepoch")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡
    model.load_state_dict(torch.load(early_stopping.best_path))
    print(f"å·²åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡: {early_stopping.best_path}")
    
    return history



# è·å–è®¾å¤‡æ•°é‡
device_count = torch_directml.device_count()
print(f"å¯ç”¨çš„ DirectML è®¾å¤‡æ•°é‡: {device_count}")

# åˆ—å‡ºæ‰€æœ‰è®¾å¤‡ä¿¡æ¯
print("è®¾å¤‡è¯¦ç»†ä¿¡æ¯:")
amd_index = None
for i in range(device_count):
    # æ³¨æ„ï¼šdevice_name() éœ€è¦æ•´æ•°ç´¢å¼•ä½œä¸ºå‚æ•°
    name = torch_directml.device_name(i)
    print(f"è®¾å¤‡ {i}: {name}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸º AMD è®¾å¤‡
    if "Radeon" in name or "AMD" in name or "MI60" in name:
        amd_index = i
        print("   --> æ£€æµ‹åˆ° AMD è®¾å¤‡!")

# é€‰æ‹© AMD è®¾å¤‡
if amd_index is not None:
    # ä½¿ç”¨ç´¢å¼•åˆ›å»ºè®¾å¤‡
    device = torch_directml.device(amd_index)
    print(f"\nâœ… å·²é€‰æ‹© AMD è®¾å¤‡ [ç´¢å¼• {amd_index}]: {torch_directml.device_name(amd_index)}")
else:
    device = torch_directml.device(0)
    print(f"\nâš ï¸ æœªæ‰¾åˆ° AMD è®¾å¤‡ï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡ [ç´¢å¼• 0]: {torch_directml.device_name(0)}")

# æ‰§è¡Œè®¡ç®—æµ‹è¯•
print("\nè¿è¡Œè®¡ç®—æµ‹è¯•...")
try:
    size = 10000
    a = torch.randn(size, size, device=device)
    b = torch.randn(size, size, device=device)
    c = torch.mm(a, b)
    c_cpu = c.cpu()  # å°†ç»“æœå¤åˆ¶å› CPU
    
    print(f"æµ‹è¯•æˆåŠŸï¼ç»“æœå½¢çŠ¶: {c.shape}")
    print(f"ä½¿ç”¨çš„è®¾å¤‡: {a.device}")
    
    # è·å–è®¾å¤‡ç´¢å¼•
    device_index = device.index if device.index is not None else 0
    print(f"è®¾å¤‡åç§°: {torch_directml.device_name(device_index)}")
    
except Exception as e:
    print(f"âŒ è®¡ç®—æµ‹è¯•å¤±è´¥: {str(e)}")


# filename="StressLevelDataset.csv"
# ç‰¹å¾é€‰æ‹©æ•°æ®
filename="dataset_top10_features.csv"

num_classes = 3  # å‡è®¾æœ‰3ä¸ªç±»åˆ«
StressLevelDataset = pd.read_csv(filename)
X=StressLevelDataset.copy()
y=X.pop('stress_level')

torch.manual_seed(42); np.random.seed(42)

# ç¡®ä¿ y ä¸º 0..num_classes-1 çš„ long tensor
if not np.issubdtype(y.dtype, np.integer):
    y = y.astype('category').cat.codes
else:
    # ä¸‡ä¸€ä¸æ˜¯ä» 0 å¼€å§‹ï¼Œåšä¸€ä¸ªæ˜ å°„
    classes = np.sort(y.unique())
    mapping = {c:i for i,c in enumerate(classes)}
    y = y.map(mapping).astype(int)

# 1. é¦–å…ˆåˆ†å‡ºæµ‹è¯•é›†ï¼ˆ15%ï¼‰
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.15, random_state=42, stratify=y
)

# 2. ç„¶ååˆ†å‡ºè®­ç»ƒé›†ï¼ˆ70%ï¼‰å’ŒéªŒè¯é›†ï¼ˆ15%ï¼‰
X_train, X_valid, y_train, y_valid = train_test_split(
    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.15/(1-0.15)â‰ˆ0.176
)

# è½¬æ¢ä¸ºTensor
X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)
y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)

X_val_tensor = torch.tensor(X_valid.to_numpy(), dtype=torch.float32)
y_val_tensor = torch.tensor(y_valid.to_numpy(), dtype=torch.long)

X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)
y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)

#åˆ›å»ºDatasetå’ŒDataLoader
batch_size = 128

train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)

val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
val_loader = DataLoader(val_dataset, batch_size=batch_size)

test_dataset = TensorDataset(X_test_tensor, y_test_tensor)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

input_shape = X_train.shape[1]
print(f"è¾“å…¥å½¢çŠ¶: {input_shape}")

# 3. åˆ›å»ºç±»ä¼¼Kerasçš„Sequentialæ¨¡å‹
# model = MLP(in_dim=input_shape, num_classes=num_classes)
# model = BLS(in_dim=input_shape, num_classes=num_classes)
model = AttentionMLP(in_dim=input_shape, num_classes=num_classes)

# 4. è®¾å¤‡è®¾ç½®
model = model.to(device)
# å¤šåˆ†ç±»ä½¿ç”¨CrossEntropyLoss (åŒ…å«softmax)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters())
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode="min", factor=0.5, patience=3, verbose=True
)
early_stopping = EarlyStopping(patience=10, min_delta=0.001, save_path="best_model.pt")

epochs=200 
patience=10
min_delta=0.001



# 6. è®­ç»ƒæ¨¡å‹ (å¯¹åº”Kerasçš„model.fit)
history = train_model(
    model, train_loader, val_loader, 
    criterion, optimizer,scheduler, early_stopping,
    epochs=200, 
    verbose=1   
)

# 7. åˆ›å»ºå†å²æ•°æ®æ¡† (å¯¹åº”Kerasçš„history_df)
history_df = pd.DataFrame(history)
history_df.to_csv('training_history.csv', index=False)
print("è®­ç»ƒå†å²å·²ä¿å­˜åˆ° training_history.csv")


# ========= 8. ç”¨æœ€ä½³æ¨¡å‹è¯„ä¼°æµ‹è¯•é›†ï¼Œå¹¶å¯¼å‡ºç»“æœ =========
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, roc_auc_score
import json

def evaluate_on_loader(model, loader, criterion, device):
    model.eval()
    test_loss = 0.0
    total = 0
    correct = 0

    all_logits = []
    all_probs = []
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)                    # (B, C) logits
            loss = criterion(outputs, labels)

            test_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)

            probs = torch.softmax(outputs, dim=1)

            all_logits.append(outputs.detach().cpu())
            all_probs.append(probs.detach().cpu())
            all_preds.append(predicted.detach().cpu())
            all_labels.append(labels.detach().cpu())

    test_loss /= total
    test_acc = 100.0 * correct / total

    all_logits = torch.cat(all_logits).numpy()
    all_probs  = torch.cat(all_probs).numpy()
    all_preds  = torch.cat(all_preds).numpy()
    all_labels = torch.cat(all_labels).numpy()

    return {
        "loss": test_loss,
        "acc": test_acc,
        "logits": all_logits,
        "probs": all_probs,
        "preds": all_preds,
        "labels": all_labels,
    }

# å¦‚æœä½ åœ¨è®­ç»ƒæœ«å°¾å·²ç» load_state_dict(best) äº†ï¼Œå½“å‰ model å°±æ˜¯æœ€ä½³æ¨¡å‹ï¼›
# è‹¥æƒ³â€œä¿é™©â€å¯å–æ¶ˆæ³¨é‡Šä¸‹ä¸€è¡Œä»ç£ç›˜å†åŠ è½½ä¸€æ¬¡
model.load_state_dict(torch.load("best_model.pt", map_location=device))

test_out = evaluate_on_loader(model, test_loader, criterion, device)

# â€”â€” è®¡ç®—æ›´ç»†æŒ‡æ ‡ â€”â€” 
precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(
    test_out["labels"], test_out["preds"], average="macro", zero_division=0
)
precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
    test_out["labels"], test_out["preds"], average="weighted", zero_division=0
)

# å¤šåˆ†ç±» AUCï¼ˆè‹¥ num_classes>2 ç”¨ OVR/å®å¹³å‡ï¼›æ¦‚ç‡å¿…é¡»æœ‰ï¼‰
auc_macro_ovr = None
try:
    if test_out["probs"].shape[1] >= 2:
        auc_macro_ovr = roc_auc_score(
            test_out["labels"],
            test_out["probs"],
            multi_class="ovr",
            average="macro"
        )
except Exception:
    pass  # æŸäº›æ•°æ®/ç±»åˆ«ä¸å¹³è¡¡ä¼šæŠ¥é”™ï¼Œè·³è¿‡å³å¯

# â€”â€” å¯¼å‡º 1) æŒ‡æ ‡æ±‡æ€»ï¼ˆtest_summary.csvï¼‰â€”â€”
summary_row = {
    "test_loss": round(test_out["loss"], 6),
    "test_acc(%)": round(test_out["acc"], 4),
    "precision_macro": round(precision_macro, 6),
    "recall_macro": round(recall_macro, 6),
    "f1_macro": round(f1_macro, 6),
    "precision_weighted": round(precision_weighted, 6),
    "recall_weighted": round(recall_weighted, 6),
    "f1_weighted": round(f1_weighted, 6),
    "auc_macro_ovr": (None if auc_macro_ovr is None else round(auc_macro_ovr, 6)),
    "num_classes": int(num_classes),
    "num_test_examples": int(len(test_loader.dataset)),
}
pd.DataFrame([summary_row]).to_csv("test_summary.csv", index=False)
print("å·²ä¿å­˜æµ‹è¯•é›†æŒ‡æ ‡ -> test_summary.csv")

# â€”â€” å¯¼å‡º 2) é¢„æµ‹æ˜ç»†ï¼ˆtest_results.csvï¼‰â€”â€”
# å°†æ¦‚ç‡åˆ—å‘½åä¸º prob_class_i
prob_cols = [f"prob_class_{i}" for i in range(test_out["probs"].shape[1])]
df_probs = pd.DataFrame(test_out["probs"], columns=prob_cols)
df_preds = pd.DataFrame({
    "y_true": test_out["labels"],
    "y_pred": test_out["preds"],
    "correct": (test_out["labels"] == test_out["preds"]).astype(int),
})

# è‹¥æƒ³æŠŠåŸå§‹ç‰¹å¾ä¸€èµ·å¯¼å‡ºï¼Œæ‹¼ä¸Š X_test
X_test_reset = X_test.reset_index(drop=True)
test_results_df = pd.concat([X_test_reset, df_preds, df_probs], axis=1)
test_results_df.to_csv("test_results.csv", index=False)
print("å·²ä¿å­˜æµ‹è¯•é›†é¢„æµ‹æ˜ç»† -> test_results.csv")

# â€”â€” å¯¼å‡º 3) æ··æ·†çŸ©é˜µï¼ˆconfusion_matrix.csvï¼‰â€”â€”
cm = confusion_matrix(test_out["labels"], test_out["preds"])
cm_df = pd.DataFrame(cm, index=[f"true_{i}" for i in range(num_classes)],
                        columns=[f"pred_{i}" for i in range(num_classes)])
cm_df.to_csv("confusion_matrix.csv")
print("å·²ä¿å­˜æ··æ·†çŸ©é˜µ -> confusion_matrix.csv")

# â€”â€” é¢å¤–ï¼šåˆ†ç±»æŠ¥å‘Šï¼ˆæ–‡æœ¬ï¼‰ï¼Œä¾¿äºå¿«é€ŸæŸ¥çœ‹ â€”â€” 
report = classification_report(test_out["labels"], test_out["preds"], digits=4, zero_division=0)
with open("classification_report.txt", "w", encoding="utf-8") as f:
    f.write(report)
print("å·²ä¿å­˜åˆ†ç±»æŠ¥å‘Š -> classification_report.txt")

print("\nã€æµ‹è¯•é›†ç»“æœæ‘˜è¦ã€‘")
print(pd.DataFrame([summary_row]))

# æ”¶é›†æ¨¡å‹é¢„æµ‹ç»“æœ
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# åˆ›å»ºé”™è¯¯åˆ†æDataFrame
error_df = pd.DataFrame({
    'true_label': y_test,
    'predicted_label': all_preds,
    'is_correct': [1 if t == p else 0 for t, p in zip(y_test, all_preds)]
})

# æ·»åŠ åŸå§‹ç‰¹å¾
error_df = pd.concat([error_df, X_test.reset_index(drop=True)], axis=1)

# åˆ†æé”™è¯¯æ ·æœ¬
incorrect_samples = error_df[error_df['is_correct'] == 0]
print(f"é”™è¯¯æ ·æœ¬æ¯”ä¾‹: {len(incorrect_samples)/len(error_df):.2%}")

# æ£€æŸ¥é”™è¯¯æ ·æœ¬çš„ç‰¹å¾åˆ†å¸ƒ
plt.figure(figsize=(12, 6))
sns.boxplot(data=incorrect_samples.drop(columns=['true_label', 'predicted_label', 'is_correct']))
plt.title('wrong predictions feature distribution')
plt.xticks(rotation=45)
plt.savefig('error_boxplog.png')
plt.show()

# æ£€æŸ¥ç‰¹å®šç‰¹å¾ä¸é”™è¯¯çš„å…³ç³»
# for feature in ['most_important_feature1', 'most_important_feature2']:
#     plt.figure(figsize=(10, 4))
#     sns.kdeplot(data=error_df, x=feature, hue='is_correct', common_norm=False)
#     plt.title(f'feature"{feature}"distribution by correctness')
#     plt.show()





